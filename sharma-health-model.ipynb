{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\muchf\\anaconda3\\lib\\site-packages (2.2.2)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: datasets in c:\\users\\muchf\\anaconda3\\lib\\site-packages (3.5.0)\n",
      "Requirement already satisfied: unsloth in c:\\users\\muchf\\anaconda3\\lib\\site-packages (2025.3.19)\n",
      "Requirement already satisfied: torch in c:\\users\\muchf\\anaconda3\\lib\\site-packages (2.5.1+cu121)\n",
      "Requirement already satisfied: transformers in c:\\users\\muchf\\anaconda3\\lib\\site-packages (4.50.2)\n",
      "Requirement already satisfied: requests in c:\\users\\muchf\\anaconda3\\lib\\site-packages (2.32.2)\n",
      "Requirement already satisfied: cupy-cuda12x in c:\\users\\muchf\\anaconda3\\lib\\site-packages (13.4.1)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\muchf\\anaconda3\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\muchf\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\muchf\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\muchf\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\muchf\\anaconda3\\lib\\site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\muchf\\anaconda3\\lib\\site-packages (from datasets) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\muchf\\anaconda3\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\muchf\\anaconda3\\lib\\site-packages (from datasets) (4.66.4)\n",
      "Requirement already satisfied: xxhash in c:\\users\\muchf\\anaconda3\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\muchf\\anaconda3\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in c:\\users\\muchf\\anaconda3\\lib\\site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.3.1)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\muchf\\anaconda3\\lib\\site-packages (from datasets) (3.9.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in c:\\users\\muchf\\anaconda3\\lib\\site-packages (from datasets) (0.29.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\muchf\\appdata\\roaming\\python\\python312\\site-packages (from datasets) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\muchf\\anaconda3\\lib\\site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: unsloth_zoo>=2025.3.17 in c:\\users\\muchf\\anaconda3\\lib\\site-packages (from unsloth) (2025.3.17)\n",
      "Requirement already satisfied: xformers>=0.0.27.post2 in c:\\users\\muchf\\anaconda3\\lib\\site-packages (from unsloth) (0.0.29.post3)\n",
      "Requirement already satisfied: bitsandbytes in c:\\users\\muchf\\anaconda3\\lib\\site-packages (from unsloth) (0.45.4)\n",
      "Requirement already satisfied: triton-windows in c:\\users\\muchf\\anaconda3\\lib\\site-packages (from unsloth) (3.2.0.post17)\n",
      "Requirement already satisfied: tyro in c:\\users\\muchf\\anaconda3\\lib\\site-packages (from unsloth) (0.9.17)\n",
      "Requirement already satisfied: sentencepiece>=0.2.0 in c:\\users\\muchf\\anaconda3\\lib\\site-packages (from unsloth) (0.2.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\muchf\\appdata\\roaming\\python\\python312\\site-packages (from unsloth) (6.0.0)\n",
      "Requirement already satisfied: wheel>=0.42.0 in c:\\users\\muchf\\anaconda3\\lib\\site-packages (from unsloth) (0.43.0)\n",
      "Requirement already satisfied: accelerate>=0.34.1 in c:\\users\\muchf\\anaconda3\\lib\\site-packages (from unsloth) (1.5.2)\n",
      "Requirement already satisfied: trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9 in c:\\users\\muchf\\anaconda3\\lib\\site-packages (from unsloth) (0.15.2)\n",
      "Requirement already satisfied: peft!=0.11.0,>=0.7.1 in c:\\users\\muchf\\anaconda3\\lib\\site-packages (from unsloth) (0.15.1)\n",
      "Requirement already satisfied: protobuf<4.0.0 in c:\\users\\muchf\\anaconda3\\lib\\site-packages (from unsloth) (3.20.3)\n",
      "Requirement already satisfied: hf_transfer in c:\\users\\muchf\\anaconda3\\lib\\site-packages (from unsloth) (0.1.9)\n",
      "Requirement already satisfied: diffusers in c:\\users\\muchf\\anaconda3\\lib\\site-packages (from unsloth) (0.32.2)\n",
      "Requirement already satisfied: torchvision in c:\\users\\muchf\\anaconda3\\lib\\site-packages (from unsloth) (0.20.1+cu121)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\muchf\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\muchf\\anaconda3\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\muchf\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\muchf\\anaconda3\\lib\\site-packages (from torch) (69.5.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\muchf\\anaconda3\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\muchf\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\muchf\\anaconda3\\lib\\site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\muchf\\anaconda3\\lib\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\muchf\\anaconda3\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\muchf\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\muchf\\anaconda3\\lib\\site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\muchf\\anaconda3\\lib\\site-packages (from requests) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\muchf\\anaconda3\\lib\\site-packages (from requests) (2024.7.4)\n",
      "Requirement already satisfied: fastrlock>=0.5 in c:\\users\\muchf\\anaconda3\\lib\\site-packages (from cupy-cuda12x) (0.8.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\muchf\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\muchf\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\muchf\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\muchf\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\muchf\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.9.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\muchf\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\muchf\\anaconda3\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: rich in c:\\users\\muchf\\appdata\\roaming\\python\\python312\\site-packages (from trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9->unsloth) (13.8.1)\n",
      "Requirement already satisfied: cut_cross_entropy in c:\\users\\muchf\\anaconda3\\lib\\site-packages (from unsloth_zoo>=2025.3.17->unsloth) (25.1.1)\n",
      "Requirement already satisfied: pillow in c:\\users\\muchf\\anaconda3\\lib\\site-packages (from unsloth_zoo>=2025.3.17->unsloth) (10.3.0)\n",
      "Collecting torch\n",
      "  Using cached torch-2.6.0-cp312-cp312-win_amd64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\muchf\\anaconda3\\lib\\site-packages (from diffusers->unsloth) (7.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\muchf\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting torchvision (from unsloth)\n",
      "  Using cached torchvision-0.21.0-cp312-cp312-win_amd64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: docstring-parser>=0.15 in c:\\users\\muchf\\anaconda3\\lib\\site-packages (from tyro->unsloth) (0.16)\n",
      "Requirement already satisfied: shtab>=1.5.6 in c:\\users\\muchf\\anaconda3\\lib\\site-packages (from tyro->unsloth) (1.7.1)\n",
      "Requirement already satisfied: typeguard>=4.0.0 in c:\\users\\muchf\\anaconda3\\lib\\site-packages (from tyro->unsloth) (4.4.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\muchf\\appdata\\roaming\\python\\python312\\site-packages (from rich->trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9->unsloth) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\muchf\\anaconda3\\lib\\site-packages (from rich->trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9->unsloth) (2.15.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\muchf\\anaconda3\\lib\\site-packages (from importlib-metadata->diffusers->unsloth) (3.17.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\muchf\\appdata\\roaming\\python\\python312\\site-packages (from markdown-it-py>=2.2.0->rich->trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9->unsloth) (0.1.2)\n",
      "Using cached torch-2.6.0-cp312-cp312-win_amd64.whl (204.1 MB)\n",
      "Using cached torchvision-0.21.0-cp312-cp312-win_amd64.whl (1.6 MB)\n",
      "Installing collected packages: torch, torchvision\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.5.1+cu121\n",
      "    Uninstalling torch-2.5.1+cu121:\n",
      "      Successfully uninstalled torch-2.5.1+cu121\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.20.1+cu121\n",
      "    Uninstalling torchvision-0.20.1+cu121:\n",
      "      Successfully uninstalled torchvision-0.20.1+cu121\n",
      "Successfully installed torch-2.6.0 torchvision-0.21.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\muchf\\anaconda3\\Lib\\site-packages\\~-rch'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchaudio 2.5.1+cu121 requires torch==2.5.1+cu121, but you have torch 2.6.0 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install pandas datasets unsloth torch transformers requests cupy-cuda12x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['input', 'instruction', 'output'], dtype='object')\n",
      "{'id': '25f54daf-eadb-4eed-a024-8e5c568723d1', 'object': 'chat.completion', 'created': 1743187043, 'model': 'deepseek-chat', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': \"**Question:** What are the common treatment options for neonatal jaundice?  \\n\\n**Answer:** The most common treatments for neonatal jaundice include:  \\n1. **Phototherapy** – Exposure to special blue-spectrum lights that help break down bilirubin in the baby's skin.  \\n2. **Frequent Feeding** – Increasing breast milk or formula intake helps promote bilirubin excretion through stool.  \\n3. **Intravenous Immunoglobulin (IVIG)** – Used in cases of severe jaundice caused by blood group incompatibility (e.g., Rh or ABO incompatibility).  \\n4. **Exchange Transfusion** – A rare but critical procedure for extreme cases where bilirubin levels are dangerously high.  \\n\\nTreatment choice depends on bilirubin levels, the baby's age, and underlying causes. Early detection and management help prevent complications like kernicterus.\"}, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 14, 'completion_tokens': 172, 'total_tokens': 186, 'prompt_tokens_details': {'cached_tokens': 0}, 'prompt_cache_hit_tokens': 0, 'prompt_cache_miss_tokens': 14}, 'system_fingerprint': 'fp_3d5141a69a_prod0225'}\n",
      "{'id': '27dc5dd5-3704-4692-85db-f1e2f59fef6e', 'object': 'chat.completion', 'created': 1743187053, 'model': 'deepseek-chat', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': '**Q:** What are the key steps in managing preeclampsia during pregnancy to ensure the safety of both the mother and baby?  \\n\\n**A:** Managing preeclampsia involves close monitoring and timely interventions to prevent complications. Key steps include:  \\n1. **Regular Monitoring:** Frequent blood pressure checks, urine tests for protein, and blood tests to assess liver/kidney function and platelet counts.  \\n2. **Antihypertensive Medications:** If blood pressure is severely elevated (e.g., ≥160/110 mmHg), medications like labetalol or nifedipine may be prescribed.  \\n3. **Magnesium Sulfate:** Administered to prevent seizures (eclampsia) in severe cases.  \\n4. **Fetal Surveillance:** Regular ultrasounds and non-stress tests to monitor the baby’s growth and well-being.  \\n5. **Delivery Planning:** The only definitive cure is delivery. Timing depends on gestational age, severity of preeclampsia, and maternal/fetal stability'}, 'logprobs': None, 'finish_reason': 'length'}], 'usage': {'prompt_tokens': 16, 'completion_tokens': 200, 'total_tokens': 216, 'prompt_tokens_details': {'cached_tokens': 0}, 'prompt_cache_hit_tokens': 0, 'prompt_cache_miss_tokens': 16}, 'system_fingerprint': 'fp_3d5141a69a_prod0225'}\n",
      "{'id': 'b17e95e3-5d5e-477f-81e6-f4bc6789dd28', 'object': 'chat.completion', 'created': 1743187064, 'model': 'deepseek-chat', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': \"**Question:**  \\n*What are the common causes and immediate management steps for postpartum hemorrhage (PPH)?*  \\n\\n**Answer:**  \\nPostpartum hemorrhage (PPH), defined as blood loss ≥500 mL after vaginal delivery or ≥1000 mL after cesarean section, is a leading cause of maternal mortality.  \\n\\n**Common Causes (4 T's Mnemonic):**  \\n1. **Tone** (Uterine atony, most common cause).  \\n2. **Trauma** (Lacerations, uterine rupture).  \\n3. **Tissue** (Retained placenta or clots).  \\n4. **Thrombin** (Coagulopathy, e.g., DIC).  \\n\\n**Immediate Management:**  \\n- **Massage the uterus** to stimulate contractions.  \\n- Administer **uterotonics** (oxytocin, misoprostol, methylergonovine).  \\n- Examine for/repair **genital tract trauma**.  \\n- Remove\"}, 'logprobs': None, 'finish_reason': 'length'}], 'usage': {'prompt_tokens': 12, 'completion_tokens': 200, 'total_tokens': 212, 'prompt_tokens_details': {'cached_tokens': 0}, 'prompt_cache_hit_tokens': 0, 'prompt_cache_miss_tokens': 12}, 'system_fingerprint': 'fp_3d5141a69a_prod0225'}\n",
      "Total entries: 2685\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset, Dataset\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# DeepSeek API setup\n",
    "DEEPSEEK_API_KEY = \"sk-732ea226899242339e5d25944abbafd7\"\n",
    "DEEPSEEK_URL = \"https://api.deepseek.com/v1/chat/completions\"\n",
    "\n",
    "# Load dataset from Hugging Face\n",
    "dataset = load_dataset(\"medalpaca/medical_meadow_medqa\")\n",
    "df = dataset[\"train\"].to_pandas()\n",
    "\n",
    "# Verify column names\n",
    "print(df.columns)  # Debugging step\n",
    "\n",
    "# Correct column names\n",
    "HEALTH_TOPICS = [\"neonatal\", \"pregnancy\", \"obgyn\", \"baby\", \"birth\", \"fetal\", \"labor\", \"ectopic\", \"preeclampsia\", \"gestation\"]\n",
    "filtered_df = df[df[\"input\"].str.lower().apply(lambda x: any(topic in x for topic in HEALTH_TOPICS))]\n",
    "\n",
    "# Generate synthetic data using DeepSeek API\n",
    "def generate_synthetic_qa(prompt):\n",
    "    payload = {\n",
    "        \"model\": \"deepseek-chat\",\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "        \"max_tokens\": 200\n",
    "    }\n",
    "    headers = {\"Authorization\": f\"Bearer {DEEPSEEK_API_KEY}\", \"Content-Type\": \"application/json\"}\n",
    "    response = requests.post(DEEPSEEK_URL, json=payload, headers=headers).json()\n",
    "\n",
    "    print(response)  # Debug API response\n",
    "\n",
    "    if \"choices\" in response:\n",
    "        return response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    else:\n",
    "        return \"Error: Invalid API Response\"\n",
    "\n",
    "synthetic_data = []\n",
    "prompts = [\n",
    "    \"Generate a question and answer about neonatal jaundice treatment.\",\n",
    "    \"Generate a Q&A pair about managing preeclampsia in pregnancy.\",\n",
    "    \"Generate a question and answer about postpartum hemorrhage.\"\n",
    "]\n",
    "\n",
    "for prompt in prompts:\n",
    "    response = generate_synthetic_qa(prompt)\n",
    "    lines = response.split(\"\\n\")\n",
    "    if len(lines) >= 2:\n",
    "        q, a = lines[0], lines[1]\n",
    "        synthetic_data.append({\"input\": q.strip(), \"output\": a.strip()})\n",
    "\n",
    "# Combine datasets\n",
    "synthetic_df = pd.DataFrame(synthetic_data)\n",
    "combined_df = pd.concat([filtered_df[[\"input\", \"output\"]], synthetic_df], ignore_index=True)\n",
    "\n",
    "# Save to JSON\n",
    "combined_df.to_json(\"health_data.json\", orient=\"records\")\n",
    "dataset = Dataset.from_pandas(combined_df)\n",
    "print(f\"Total entries: {len(combined_df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Unsloth: No NVIDIA GPU found? Unsloth currently only supports GPUs!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01munsloth\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FastLanguageModel\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# DeepSeek API setup\u001b[39;00m\n\u001b[0;32m      8\u001b[0m DEEPSEEK_API_KEY \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msk-732ea226899242339e5d25944abbafd7\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\muchf\\anaconda3\\Lib\\site-packages\\unsloth\\__init__.py:93\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;66;03m# First check if CUDA is available ie a NVIDIA GPU is seen\u001b[39;00m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[1;32m---> 93\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsloth: No NVIDIA GPU found? Unsloth currently only supports GPUs!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     95\u001b[0m \u001b[38;5;66;03m# Fix Xformers performance issues since 0.0.25\u001b[39;00m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mimportlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: Unsloth: No NVIDIA GPU found? Unsloth currently only supports GPUs!"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset, Dataset\n",
    "import requests\n",
    "import json\n",
    "from unsloth import FastLanguageModel\n",
    "\n",
    "# DeepSeek API setup\n",
    "DEEPSEEK_API_KEY = \"sk-732ea226899242339e5d25944abbafd7\"\n",
    "DEEPSEEK_URL = \"https://api.deepseek.com/v1/chat/completions\"\n",
    "\n",
    "# Load dataset from Hugging Face\n",
    "dataset = load_dataset(\"medalpaca/medical_meadow_medqa\")\n",
    "df = dataset[\"train\"].to_pandas()\n",
    "\n",
    "# Verify column names\n",
    "print(\"Columns in dataset:\", df.columns)\n",
    "\n",
    "# Define relevant health topics\n",
    "HEALTH_TOPICS = [\"neonatal\", \"pregnancy\", \"obgyn\", \"baby\", \"birth\", \"fetal\", \"labor\", \"ectopic\", \"preeclampsia\", \"gestation\"]\n",
    "\n",
    "# Filter for relevant topics (CPU-based)\n",
    "filtered_df = df[df[\"input\"].str.lower().apply(lambda x: any(topic in x for topic in HEALTH_TOPICS))]\n",
    "print(f\"Filtered entries: {len(filtered_df)}\")\n",
    "\n",
    "# Generate synthetic data using DeepSeek API\n",
    "def generate_synthetic_qa(prompt):\n",
    "    payload = {\n",
    "        \"model\": \"deepseek-chat\",\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "        \"max_tokens\": 200\n",
    "    }\n",
    "    headers = {\"Authorization\": f\"Bearer {DEEPSEEK_API_KEY}\", \"Content-Type\": \"application/json\"}\n",
    "    response = requests.post(DEEPSEEK_URL, json=payload, headers=headers).json()\n",
    "\n",
    "    print(\"API Response:\", response)\n",
    "\n",
    "    if \"choices\" in response and response[\"choices\"]:\n",
    "        content = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "        lines = [line.strip() for line in content.split(\"\\n\") if line.strip()]\n",
    "        if len(lines) >= 2:\n",
    "            return lines[0], lines[1]\n",
    "        else:\n",
    "            return \"Error: Unexpected format\", content\n",
    "    else:\n",
    "        return \"Error: Invalid API Response\", \"No content\"\n",
    "\n",
    "synthetic_data = []\n",
    "prompts = [\n",
    "    \"Generate a question and answer about neonatal jaundice treatment.\",\n",
    "    \"Generate a Q&A pair about managing preeclampsia in pregnancy.\",\n",
    "    \"Generate a question and answer about postpartum hemorrhage.\"\n",
    "]\n",
    "\n",
    "for prompt in prompts:\n",
    "    question, answer = generate_synthetic_qa(prompt)\n",
    "    synthetic_data.append({\"input\": question, \"output\": answer})\n",
    "\n",
    "# Combine datasets\n",
    "synthetic_df = pd.DataFrame(synthetic_data)\n",
    "combined_df = pd.concat([filtered_df[[\"input\", \"output\"]], synthetic_df], ignore_index=True)\n",
    "\n",
    "# Save to JSON\n",
    "combined_df.to_json(\"health_data.json\", orient=\"records\")\n",
    "dataset = Dataset.from_pandas(combined_df)\n",
    "print(f\"Total entries: {len(combined_df)}\")\n",
    "\n",
    "# Fine-tuning with unsloth\n",
    "print(\"Starting fine-tuning...\")\n",
    "model_name = \"unsloth/DeepSeek-R1-Distill-Llama-8B\"  # Base model\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=model_name,\n",
    "    max_seq_length=2048,\n",
    "    dtype=None,  # Auto-detect\n",
    "    load_in_4bit=True  # For efficiency\n",
    ")\n",
    "\n",
    "# Load the dataset\n",
    "dataset = load_dataset(\"json\", data_files=\"health_data.json\")[\"train\"]\n",
    "\n",
    "# Define prompt template\n",
    "prompt_template = \"\"\"### Instruction: You are Sharma, a medical expert specializing in neonatal, pregnancy, and OB-GYN cases. Respond only to health queries in these areas. For non-relevant queries, say: \"I’m specialized in neonatal, pregnancy, and OB-GYN cases only. Please ask a related question.\"\n",
    "Question: {input}\n",
    "Answer: {output}\"\"\"\n",
    "\n",
    "def format_prompt(example):\n",
    "    return {\"text\": prompt_template.format(input=example[\"input\"], output=example[\"output\"])}\n",
    "\n",
    "dataset = dataset.map(format_prompt)\n",
    "\n",
    "# Fine-tune with LoRA\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r=16,  # LoRA rank\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0\n",
    ")\n",
    "\n",
    "trainer = FastLanguageModel.Trainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=dataset,\n",
    "    args={\n",
    "        \"per_device_train_batch_size\": 2,\n",
    "        \"gradient_accumulation_steps\": 4,\n",
    "        \"max_steps\": 500,\n",
    "        \"learning_rate\": 2e-4,\n",
    "        \"fp16\": True,\n",
    "        \"logging_steps\": 10\n",
    "    }\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "# Save the fine-tuned model\n",
    "model.save_pretrained(\"sharma-health-model\")\n",
    "tokenizer.save_pretrained(\"sharma-health-model\")\n",
    "print(\"Model saved to 'sharma-health-model'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in dataset: Index(['input', 'instruction', 'output'], dtype='object')\n",
      "Filtered entries: 2682\n",
      "API Response: {'id': '6acac08f-ca57-4f80-bbc1-0ff80cafb31f', 'object': 'chat.completion', 'created': 1743199914, 'model': 'deepseek-chat', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': \"**Question:**  \\nWhat is the most common and effective treatment for neonatal jaundice caused by elevated bilirubin levels?  \\n\\n**Answer:**  \\nThe most common and effective treatment for neonatal jaundice is **phototherapy**, which uses special blue-spectrum light to break down bilirubin in the baby's skin, making it easier for the body to eliminate. In severe cases, an **exchange transfusion** may be required to rapidly lower bilirubin levels. Treatment decisions are based on the infant's age, bilirubin levels, and overall health. Early feeding (breastfeeding or formula) also helps by promoting bilirubin excretion through stool.  \\n\\nWould you like additional details on treatment thresholds or side effects?\"}, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 14, 'completion_tokens': 139, 'total_tokens': 153, 'prompt_tokens_details': {'cached_tokens': 0}, 'prompt_cache_hit_tokens': 0, 'prompt_cache_miss_tokens': 14}, 'system_fingerprint': 'fp_3d5141a69a_prod0225'}\n",
      "API Response: {'id': '29212c8e-2273-44d7-ace4-720100f57af1', 'object': 'chat.completion', 'created': 1743199923, 'model': 'deepseek-chat', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': '**Q: What are the key steps in managing preeclampsia during pregnancy?**  \\n\\n**A:** Managing preeclampsia involves close monitoring and timely interventions to protect both the mother and baby. Key steps include:  \\n1. **Regular Monitoring** – Frequent blood pressure checks, urine tests for protein, and blood tests to assess liver/kidney function.  \\n2. **Medications** – Antihypertensive drugs (e.g., labetalol, nifedipine) to control severe hypertension, and magnesium sulfate to prevent seizures (eclampsia).  \\n3. **Delivery Planning** – The only cure for preeclampsia is delivery. Timing depends on gestational age and severity; early delivery may be needed in severe cases.  \\n4. **Lifestyle Adjustments** – Reduced activity, increased rest, and sometimes hospitalization for severe cases.  \\n5. **Fetal Surveillance** – Regular ultrasounds and non-stress tests to monitor baby’s growth and well-being.  \\n\\n'}, 'logprobs': None, 'finish_reason': 'length'}], 'usage': {'prompt_tokens': 16, 'completion_tokens': 200, 'total_tokens': 216, 'prompt_tokens_details': {'cached_tokens': 0}, 'prompt_cache_hit_tokens': 0, 'prompt_cache_miss_tokens': 16}, 'system_fingerprint': 'fp_3d5141a69a_prod0225'}\n",
      "API Response: {'id': '3074db77-5000-485f-8d5f-9719f49aa76d', 'object': 'chat.completion', 'created': 1743199933, 'model': 'deepseek-chat', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': '**Question:**  \\nWhat are the common causes and immediate management steps for postpartum hemorrhage (PPH)?  \\n\\n**Answer:**  \\n**Common Causes of PPH (the \"4 T\\'s\"):**  \\n1. **Tone** (Uterine atony – most common cause, ~70% of cases).  \\n2. **Trauma** (Lacerations, uterine rupture, or hematoma).  \\n3. **Tissue** (Retained placental fragments or abnormal adherence).  \\n4. **Thrombin** (Coagulation disorders, e.g., DIC).  \\n\\n**Immediate Management:**  \\n1. **Massage the uterus** to stimulate contractions.  \\n2. **Administer uterotonics** (e.g., oxytocin, misoprostol).  \\n3. **IV fluids and blood transfusion** if needed.  \\n4. **Examine for/treat trauma** (e.g., repair lacerations).  \\n5. **Surgical interventions'}, 'logprobs': None, 'finish_reason': 'length'}], 'usage': {'prompt_tokens': 12, 'completion_tokens': 200, 'total_tokens': 212, 'prompt_tokens_details': {'cached_tokens': 0}, 'prompt_cache_hit_tokens': 0, 'prompt_cache_miss_tokens': 12}, 'system_fingerprint': 'fp_3d5141a69a_prod0225'}\n",
      "Total entries: 2685\n",
      "Starting fine-tuning...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64b1810879b64b05967303b390313f67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2685 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0affbf97e1fa40628bd0f92e44680fff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2685 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1208' max='1208' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1208/1208 56:50, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>4.110200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.445700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2.316300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2.079200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.903600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.711900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.698400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.627300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.518900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.540100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.477000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.404100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1.596400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1.456500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.419200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.533900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1.389300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1.475900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1.280000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.372200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1.427800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1.466500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1.441900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1.299200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.315800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1.252300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1.326300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1.464300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1.248100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.327500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>1.441300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1.526600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1.255800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1.290400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1.530900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1.196000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>1.492600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>1.206200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>1.147700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.227900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>1.358100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>1.324900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>1.262700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>1.279100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>1.179000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>1.584500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>1.350200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>1.157900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>1.270100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.251300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>1.342600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>1.169900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>1.378900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>1.380800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>1.321200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>1.354400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>1.259000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>1.301600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>1.249200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.377800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>1.211900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>1.282600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>1.328600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>1.134500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>1.285900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>1.294300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>1.348200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>1.296300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>1.183000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>1.215200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>1.127600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>1.064900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>1.396300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>1.307600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>1.247200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>1.293800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>1.309800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>1.034200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>1.342700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>1.177500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>1.261400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>1.450900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>1.172500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>1.186800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>1.280100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>1.157800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>1.181300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>1.188800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>1.309500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>1.092900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>1.164800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>1.147400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>1.230200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>1.130100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>1.379800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>1.221600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>1.215300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>1.292600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>1.375400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.327800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1010</td>\n",
       "      <td>1.294400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>1.179000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1030</td>\n",
       "      <td>1.078000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1040</td>\n",
       "      <td>1.160500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>1.189000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1060</td>\n",
       "      <td>1.208800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1070</td>\n",
       "      <td>1.163300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>1.178900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1090</td>\n",
       "      <td>1.378800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>1.164600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1110</td>\n",
       "      <td>1.292100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1120</td>\n",
       "      <td>1.255200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1130</td>\n",
       "      <td>1.108100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>1.368000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>1.192100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1160</td>\n",
       "      <td>1.140700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1170</td>\n",
       "      <td>1.288600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1180</td>\n",
       "      <td>1.405700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1190</td>\n",
       "      <td>1.303100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>1.095500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to 'sharma-health-model'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset, Dataset\n",
    "import requests\n",
    "import json\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, Trainer, TrainingArguments\n",
    "\n",
    "# DeepSeek API setup\n",
    "DEEPSEEK_API_KEY = \"sk-732ea226899242339e5d25944abbafd7\"\n",
    "DEEPSEEK_URL = \"https://api.deepseek.com/v1/chat/completions\"\n",
    "\n",
    "# Load dataset from Hugging Face\n",
    "dataset = load_dataset(\"medalpaca/medical_meadow_medqa\")\n",
    "df = dataset[\"train\"].to_pandas()\n",
    "\n",
    "# Verify column names\n",
    "print(\"Columns in dataset:\", df.columns)\n",
    "\n",
    "# Define relevant health topics\n",
    "HEALTH_TOPICS = [\"neonatal\", \"pregnancy\", \"obgyn\", \"baby\", \"birth\", \"fetal\", \"labor\", \"ectopic\", \"preeclampsia\", \"gestation\"]\n",
    "\n",
    "# Filter for relevant topics\n",
    "filtered_df = df[df[\"input\"].str.lower().apply(lambda x: any(topic in x for topic in HEALTH_TOPICS))]\n",
    "print(f\"Filtered entries: {len(filtered_df)}\")\n",
    "\n",
    "# Generate synthetic data using DeepSeek API\n",
    "def generate_synthetic_qa(prompt):\n",
    "    payload = {\n",
    "        \"model\": \"deepseek-chat\",\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "        \"max_tokens\": 200\n",
    "    }\n",
    "    headers = {\"Authorization\": f\"Bearer {DEEPSEEK_API_KEY}\", \"Content-Type\": \"application/json\"}\n",
    "    response = requests.post(DEEPSEEK_URL, json=payload, headers=headers).json()\n",
    "    print(\"API Response:\", response)\n",
    "    if \"choices\" in response and response[\"choices\"]:\n",
    "        content = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "        lines = [line.strip() for line in content.split(\"\\n\") if line.strip()]\n",
    "        if len(lines) >= 2:\n",
    "            return lines[0], lines[1]\n",
    "        else:\n",
    "            return \"Error: Unexpected format\", content\n",
    "    else:\n",
    "        return \"Error: Invalid API Response\", \"No content\"\n",
    "\n",
    "synthetic_data = []\n",
    "prompts = [\n",
    "    \"Generate a question and answer about neonatal jaundice treatment.\",\n",
    "    \"Generate a Q&A pair about managing preeclampsia in pregnancy.\",\n",
    "    \"Generate a question and answer about postpartum hemorrhage.\"\n",
    "]\n",
    "\n",
    "for prompt in prompts:\n",
    "    question, answer = generate_synthetic_qa(prompt)\n",
    "    synthetic_data.append({\"input\": question, \"output\": answer})\n",
    "\n",
    "# Combine datasets\n",
    "synthetic_df = pd.DataFrame(synthetic_data)\n",
    "combined_df = pd.concat([filtered_df[[\"input\", \"output\"]], synthetic_df], ignore_index=True)\n",
    "\n",
    "# Save to JSON\n",
    "combined_df.to_json(\"health_data.json\", orient=\"records\")\n",
    "dataset = Dataset.from_pandas(combined_df)\n",
    "print(f\"Total entries: {len(combined_df)}\")\n",
    "\n",
    "# Fine-tuning with transformers\n",
    "print(\"Starting fine-tuning...\")\n",
    "model_name = \"distilgpt2\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token  # Set padding token\n",
    "\n",
    "# Prepare dataset\n",
    "prompt_template = \"\"\"### Instruction: You are Sharma, a medical expert specializing in neonatal, pregnancy, and OB-GYN cases. Respond only to health queries in these areas. For non-relevant queries, say: \"I’m specialized in neonatal, pregnancy, and OB-GYN cases only. Please ask a related question.\"\n",
    "Question: {input}\n",
    "Answer: {output}\"\"\"\n",
    "\n",
    "def format_prompt(example):\n",
    "    return prompt_template.format(input=example[\"input\"], output=example[\"output\"])\n",
    "\n",
    "dataset = dataset.map(lambda x: {\"text\": format_prompt(x)})\n",
    "\n",
    "# Tokenize and prepare labels\n",
    "def tokenize_function(examples):\n",
    "    encodings = tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=512)\n",
    "    encodings[\"labels\"] = encodings[\"input_ids\"].copy()  # Labels are the same as input_ids for causal LM\n",
    "    return encodings\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "tokenized_dataset = tokenized_dataset.remove_columns([\"text\", \"input\", \"output\"])  # Remove unnecessary columns\n",
    "tokenized_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "# Split dataset\n",
    "train_dataset = tokenized_dataset.shuffle(seed=42).select(range(int(len(tokenized_dataset) * 0.9)))\n",
    "eval_dataset = tokenized_dataset.shuffle(seed=42).select(range(int(len(tokenized_dataset) * 0.9), len(tokenized_dataset)))\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./sharma-health-model\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=2,\n",
    "    save_steps=500,\n",
    "    save_total_limit=2,\n",
    "    logging_steps=10,\n",
    "    learning_rate=2e-5,\n",
    "    fp16=False,\n",
    ")\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Save the fine-tuned model\n",
    "model.save_pretrained(\"sharma-health-model\")\n",
    "tokenizer.save_pretrained(\"sharma-health-model\")\n",
    "print(\"Model saved to 'sharma-health-model'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
